# Sentiment-based-Image-Captioning
Captioning an image based on the sentiment based text data

Repository for the Final Project of E533: Deep Learning Systems course taken at Indiana University Bloomington


The project uses Tensorflow 2.0 for generating captions with sentiments and without sentiments

   
**checkpoints:** contains the checkpoints of models that have been trained as a part of this project

**pycocotools:** contains the scrpts taken from the github repository by tylin availabel [here] (https://github.com/tylin/coco-caption) to calculate the metrics such as BLEU, ROUGE-L,METEOR and CIDEr used to evaluate the quality of captions genrated by our models

`results_without_sentiment_inceptionV3.json` file contains the captions without sentiment generated by the model which uses InceptionV3 as the architecture for CNN in the encoder

`results_without_sentiment_mobilenetV2.json` file contains the captions without sentiment generated by the model which uses MobilenetV2 as the architecture for CNN in the encoder

`senticap_dataset.json` file contains the original captions available as a part of the SentiCap dataset

`sentiment_actual_negative.json` contains the actual captions with negative sentiments for the images from SentiCap dataset

`sentiment_actual_neutral.json` contains the actual captions with neutral sentiments for the images from SentiCap dataset (captions have been obtained from MS-COCO dataset)

`sentiment_actual_positive.json` contains the actual captions with positive sentiments for the images from SentiCap dataset

`sentiment_image_captioning.py` is the script used to train the model which can predict captions with sentiments. The corresponding checkpoints are stored in **sentiment** folder in the **checkpoints** folder

`sentiment_image_captioning_metrics_calculation.py` is the script used to calculate the metrics for the captions predicted by the model which predicts captions with sentiment. It uses the checkpoints stored in **sentiment** folder in the **checkpoints** folder to load the weights of the model

`sentiment_results_negative.json` contains the captions with negative sentiment predicted by the model which can predict captions with sentiments

`sentiment_results_neutral.json` contains the captions with neutral sentiment predicted by the model which can predict captions with sentiments

`sentiment_results_positive.json` contains the captions with positive sentiment predicted by the model which can predict captions with sentiments

`without_sentiment_image_captioning_inceptionV3.py` is the script used to train the model which can predict captions without sentiments and uses InceptionV3 as the architecture for CNN in the encoder. The corresponding checkpoints are stored in **without_sentiment_inceptionV3** folder in the **checkpoints** folder

`without_sentiment_image_captioning_inceptionV3_metrics_calculation.py` is the script used to calculate the metrics for the captions predicted by the model which predicts captions without sentiment and uses InceptionV3 as the architecture for CNN in the encoder. It uses the checkpoints stored in **without_sentiment_inceptionV3** folder in the **checkpoints** folder to load the weights of the model

`without_sentiment_image_captioning_mobilenetV2.py` is the script used to train the model which can predict captions without sentiments and uses MobilenetV2 as the architecture for CNN in the encoder. The corresponding checkpoints are stored in **without_sentiment_mobilenetV2** folder in the **checkpoints** folder

`without_sentiment_image_captioning_mobilenetV2_metrics_calculation.py` is the script used to calculate the metrics for the captions predicted by the model which predicts captions without sentiment and uses MobilenetV2 as the architecture for CNN in the encoder. It uses the checkpoints stored in **without_sentiment_mobilenetV2** folder in the **checkpoints** folder to load the weights of the model